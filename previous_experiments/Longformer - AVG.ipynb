{"cells":[{"cell_type":"code","execution_count":42,"metadata":{"id":"duFkfSQjAc8u","executionInfo":{"status":"ok","timestamp":1655749698029,"user_tz":-180,"elapsed":110029,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"528abc42-ed16-4922-8c47-72230af70455"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 421.8 MB 21 kB/s \n","\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n","\u001b[K     |████████████████████████████████| 3.8 MB 65.0 MB/s \n","\u001b[K     |████████████████████████████████| 448 kB 81.2 MB/s \n","\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-models-official 2.7.0 requires tensorflow>=2.7.0, but you have tensorflow 2.1.0 which is incompatible.\n","tensorflow-text 2.8.2 requires tensorflow<2.9,>=2.8.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.1.0 which is incompatible.\n","tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[K     - 668.6 MB 261 kB/s\n","\u001b[K     |████████████████████████████████| 5.8 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 78.9 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q pandas\n","!pip install -q pyyaml h5py\n","!pip install -q transformers wandb\n","\n","!pip install -q -U tensorflow-text==2.8.*\n","!pip install -q tf-models-official==2.7.0"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"sLvIkDWT1t2J","executionInfo":{"status":"ok","timestamp":1655749738154,"user_tz":-180,"elapsed":212,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["import os\n","import json\n","import random\n","import numpy as np\n","import pandas as pd\n","\n","from datetime import datetime\n","from pprint import pprint"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1596,"status":"ok","timestamp":1655749740459,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"sFzmyYG419Pz","outputId":"9dd0e73d-235a-4dc5-f114-1183881e4665"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DRIVE = \"/content/drive/MyDrive/ColabData/\""]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1655749740777,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"dDAKyCvv2E4m"},"outputs":[],"source":["# import wandb\n","# from wandb.keras import WandbCallback\n","\n","# wandb.login()\n","# WANDB_PROJECT_NAME = \"fine-tuned_longformer_cybsersecurity_news_filter\"\n","\n","# wandb.init(project=WANDB_PROJECT_NAME, resume=True, config={\"hyper\": \"parameter\"})"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1655749740777,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"6nzVX4LA2j3D","outputId":"ba51acb1-7270-4bb2-9033-126fca003675"},"outputs":[{"output_type":"stream","name":"stdout","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `2.1.0`. This will be interpreted as: `2.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","Num GPUs Available:  0\n","TF version 2.8.2\n"]}],"source":["%tensorflow_version 2.1.0\n","import tensorflow as tf\n","\n","physical_devices = tf.config.list_physical_devices('GPU')\n","print(\"Num GPUs Available: \", len(physical_devices))\n","# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n","\n","from transformers import AutoConfig\n","from transformers import AutoTokenizer\n","from transformers import TFAutoModel\n","from official.nlp import optimization  # to create AdamW optimizer\n","\n","print('TF version',tf.__version__)\n","tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})"]},{"cell_type":"code","source":["# import os\n","\n","# if os.environ['COLAB_TPU_ADDR']:\n","#   cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","#   tf.config.experimental_connect_to_cluster(cluster_resolver)\n","#   tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n","#   strategy = tf.distribute.TPUStrategy(cluster_resolver)\n","#   print('Using TPU')\n","# elif tf.config.list_physical_devices('GPU'):\n","#   strategy = tf.distribute.MirroredStrategy()\n","#   print('Using GPU')\n","# else:\n","#   raise ValueError('Running on CPU is not recommended.')"],"metadata":{"id":"O4wIfu3pH3Be","executionInfo":{"status":"ok","timestamp":1655749741119,"user_tz":-180,"elapsed":3,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i1teZOlV_30Z","executionInfo":{"status":"ok","timestamp":1655749753206,"user_tz":-180,"elapsed":12090,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"outputId":"b5505311-add8-4aa1-bbcb-fc2f85e38e81"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on TPU  ['10.54.86.122:8470']\n","INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:TPU system grpc://10.54.86.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.54.86.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.54.86.122:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.54.86.122:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":1950,"status":"ok","timestamp":1655749755152,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"qjAAmKpo2_vA"},"outputs":[],"source":["MODEL_MAX_LENGTH=4096\n","# BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_syn\n","\n","tokenizer_path = \"allenai/longformer-base-4096\"\n","tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n","\n","model_path = \"allenai/longformer-base-4096\"\n","\n","config = AutoConfig.from_pretrained(model_path)\n","config.num_labels = 2\n","config.id2label = {0: \"irrelevant\", 1: \"relevant\"}\n","config.attention_window = 128\n","\n","# longformer = TFAutoModel.from_pretrained(model_path, config=config)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655749755152,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"Ehr9MY132EtY","outputId":"c763310f-551e-419a-90a1-df4c28b3973c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["            source  year  label  \\\n","0  arstechnica.com  2020      0   \n","1  arstechnica.com  2020      0   \n","2  arstechnica.com  2020      0   \n","3  arstechnica.com  2020      0   \n","4  arstechnica.com  2020      0   \n","\n","                                               title  \\\n","0  Apple has finally embraced key-based 2FA. So s...   \n","1  Iran state hackers caught with their pants dow...   \n","2  Musk, Obama, Biden, Bezos, Gates—bitcoin scam ...   \n","3  Russia-linked hackers accused of targeting COV...   \n","4  Twitter lost control of its internal systems t...   \n","\n","                                                text  \n","0  Almost three years ago Google introduced its A...  \n","1  Iranian state hackers got caught with their pa...  \n","2  Twitter accounts of the rich and famous includ...  \n","3  Hackers backed by the Russian state are target...  \n","4  Twitter lost control of its internal systems t...  "],"text/html":["\n","  <div id=\"df-dfd1de10-1a01-4715-8114-7036504381e4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>source</th>\n","      <th>year</th>\n","      <th>label</th>\n","      <th>title</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>arstechnica.com</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>Apple has finally embraced key-based 2FA. So s...</td>\n","      <td>Almost three years ago Google introduced its A...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>arstechnica.com</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>Iran state hackers caught with their pants dow...</td>\n","      <td>Iranian state hackers got caught with their pa...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>arstechnica.com</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>Musk, Obama, Biden, Bezos, Gates—bitcoin scam ...</td>\n","      <td>Twitter accounts of the rich and famous includ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>arstechnica.com</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>Russia-linked hackers accused of targeting COV...</td>\n","      <td>Hackers backed by the Russian state are target...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>arstechnica.com</td>\n","      <td>2020</td>\n","      <td>0</td>\n","      <td>Twitter lost control of its internal systems t...</td>\n","      <td>Twitter lost control of its internal systems t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfd1de10-1a01-4715-8114-7036504381e4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-dfd1de10-1a01-4715-8114-7036504381e4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-dfd1de10-1a01-4715-8114-7036504381e4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}],"source":["dataset_path = os.path.join(DRIVE, \"text_classification_dataset_2.pickle\")\n","ds = pd.read_pickle(dataset_path)\n","\n","ds.head()"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"W8pq1Xbgj_DV","executionInfo":{"status":"ok","timestamp":1655749755153,"user_tz":-180,"elapsed":19,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["texts = ds[\"text\"].to_list()\n","labels = ds[\"label\"].to_list()"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"C5oBNAhj5cne","executionInfo":{"status":"ok","timestamp":1655749755153,"user_tz":-180,"elapsed":19,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","def split(texts, labels):\n","    train_texts, test_texts, train_labels, test_labels = train_test_split(texts, labels, stratify=labels, test_size=0.20, random_state=42)\n","    train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, stratify=train_labels, test_size=0.25, random_state=42)\n","\n","    return train_texts, train_labels, val_texts, val_labels, test_texts, test_labels\n","  \n","train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = split(texts, labels) # 20% test, 20% validation, 60% train"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1655749755153,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"Yvf3FvTh5W2Z","outputId":"a0e39965-361b-4845-b966-4717c0a289a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Weight for irrelevant samples (0): 1.51\n","Weight for relevant samples (1): 0.75\n"]}],"source":["relevant, irrelevant = np.bincount(train_labels)\n","total = relevant + irrelevant\n","\n","weight_for_0 = (1 / irrelevant) * (total) / 2.0 \n","weight_for_1 = (1 / relevant) * (total) / 2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print('Weight for irrelevant samples (0): {:.2f}'.format(weight_for_0))\n","print('Weight for relevant samples (1): {:.2f}'.format(weight_for_1))"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"jeutcb6n3RJH","executionInfo":{"status":"ok","timestamp":1655749760889,"user_tz":-180,"elapsed":5752,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["def tokenize(texts):\n","    tokenized_texts = tokenizer(texts, truncation=True, padding=True, return_tensors=\"np\")\n","    return tokenized_texts\n","\n","def format_input(texts, labels):\n","    inputs = tokenize(texts).data\n","    labels = np.asarray(labels).astype('float16').reshape((-1,1))\n","\n","    return inputs, labels\n","\n","# train_inputs, train_labels = format_input(train_texts, train_labels)\n","# val_inputs, val_labels = format_input(val_texts, val_labels)\n","# test_inputs, test_labels = format_input(test_texts, test_labels)"]},{"cell_type":"code","source":["print(len(train_labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaVmNWnGRSx-","executionInfo":{"status":"ok","timestamp":1655749760890,"user_tz":-180,"elapsed":23,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"outputId":"0c18e1aa-b053-4dda-89c0-babd886e0487"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["1638\n"]}]},{"cell_type":"code","execution_count":56,"metadata":{"id":"zLRCTX_nFBXe","executionInfo":{"status":"ok","timestamp":1655749760890,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["# train_tokens = train_inputs['input_ids']\n","# train_attention = train_inputs['attention_mask']\n","\n","# val_tokens = val_inputs['input_ids']\n","# val_attention = val_inputs['attention_mask']"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"UacwcUIE220c","executionInfo":{"status":"ok","timestamp":1655749760890,"user_tz":-180,"elapsed":20,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["# Experiment 1 - CLS\n","\n","# version = \"cls\"\n","# def create_cls_model():\n","#     input_ids = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"input_ids\", dtype=tf.int32)\n","#     attention_mask = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"attention_mask\", dtype=tf.int32)\n","    \n","#     longformer_output = longformer([input_ids, attention_mask])\n","#     cls_output = longformer_output[\"last_hidden_state\"][:,0,:]\n","    \n","#     hidden = tf.keras.layers.Dense(32, activation=\"tanh\", name=\"tanh\")(cls_output)\n","#     output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(hidden)\n","#     model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[output])\n","\n","#     return model\n"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"2R9I3vrtHpw6","executionInfo":{"status":"ok","timestamp":1655749760891,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["# Experiment 2 - word embeddings average.\n","\n","version = \"avg_embeddings\"\n","\n","def create_avg_model(base_model):\n","\n","    input_ids = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"input_ids\", dtype=tf.int32)\n","    attention_mask = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"attention_mask\", dtype=tf.int32)\n","    \n","    longformer_output = base_model([input_ids, attention_mask])\n","    avg_output = tf.keras.layers.GlobalAveragePooling1D()(longformer_output.last_hidden_state, mask=attention_mask)\n","    hidden = tf.keras.layers.Dense(32, activation=\"tanh\")(avg_output)\n","    output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(hidden)\n","    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[output])\n","\n","    return model\n"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655749760891,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"XL7h0bHgGtA3"},"outputs":[],"source":["# Experiment 3 - Longformer + CNN\n","\n","# version = \"cnn\"\n","# def create_cnn_model():\n","#     input_ids = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"input_ids\", dtype=tf.int32)\n","#     attention_mask = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"attention_mask\", dtype=tf.int32)\n","    \n","#     longformer_output = longformer([input_ids, attention_mask])\n","#     net = longformer_output[\"last_hidden_state\"]\n","\n","#     net = tf.keras.layers.Conv1D(16, (2), activation='relu')(net)\n","#     output = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(net)\n","#     model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[net])\n","\n","#     return model\n"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"0XM1FN_kGg7b","executionInfo":{"status":"ok","timestamp":1655749760891,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["# Experiment 4: use pooler output layer with dropout.\n","\n","# version = \"pooler\"\n","# def create_pooler_model():\n","#     input_ids = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"input_ids\", dtype=tf.int32)\n","#     attention_mask = tf.keras.layers.Input((MODEL_MAX_LENGTH,), name=\"attention_mask\", dtype=tf.int32)\n","\n","#     longformer_output = longformer([input_ids, attention_mask])\n","#     net = longformer_output['pooler_output']\n","    \n","#     # net = tf.keras.layers.Dropout(0.1)(net)\n","#     net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n","#     model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=[net])\n","    \n","#     return model\n"]},{"cell_type":"code","source":["import numpy as np \n","from tensorflow import keras\n","from matplotlib import pyplot as plt\n","from IPython.display import clear_output\n","\n","class PlotLearning(tf.keras.callbacks.Callback):\n","    \"\"\"\n","    Callback to plot the learning curves of the model during training.\n","    \"\"\"\n","    def on_train_begin(self, logs={}):\n","        self.metrics = {}\n","        for metric in logs:\n","            self.metrics[metric] = []\n","            \n","\n","    def on_epoch_end(self, epoch, logs={}):\n","        # Storing metrics\n","        for metric in logs:\n","            if metric in self.metrics:\n","                self.metrics[metric].append(logs.get(metric))\n","            else:\n","                self.metrics[metric] = [logs.get(metric)]\n","        \n","        # Plotting\n","        metrics = [x for x in logs if 'val' not in x]\n","        \n","        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n","        clear_output(wait=True)\n","\n","        for i, metric in enumerate(metrics):\n","            axs[i].plot(range(1, epoch + 2), \n","                        self.metrics[metric], \n","                        label=metric)\n","            if logs['val_' + metric]:\n","                axs[i].plot(range(1, epoch + 2), \n","                            self.metrics['val_' + metric], \n","                            label='val_' + metric)\n","                \n","            axs[i].legend()\n","            axs[i].grid()\n","\n","        plt.tight_layout()\n","        plt.show()"],"metadata":{"id":"uc9yBoMrKN0E","executionInfo":{"status":"ok","timestamp":1655749760891,"user_tz":-180,"elapsed":20,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","execution_count":62,"metadata":{"id":"UB8uYqqYIh8M","executionInfo":{"status":"ok","timestamp":1655749760892,"user_tz":-180,"elapsed":21,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["checkpoint_path = os.path.join(DRIVE, f\"checkpoints/tf_longformer_{version}\")\n","\n","# Define callbacks\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_path, \n","    verbose=1, \n","    save_weights_only=True,\n","    save_best_only=True,\n","    save_freq='epoch'\n",")\n","\n","# Use this callback to stop after one epoch if the loss does not improve.\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","train_inputs, train_labels = format_input(train_texts, train_labels)\n","val_inputs, val_labels = format_input(val_texts, val_labels)\n","test_inputs, test_labels = format_input(test_texts, test_labels)\n","\n","train_tokens = train_inputs['input_ids']\n","train_attention = train_inputs['attention_mask']\n","\n","val_tokens = val_inputs['input_ids']\n","val_attention = val_inputs['attention_mask']\n","\n","\n","print(f'Fine tuning {version} model...')\n","\n","with tpu_strategy.scope():\n","    loss = tf.keras.losses.BinaryCrossentropy()\n","    metrics = tf.metrics.BinaryAccuracy()\n","\n","    epochs = 14\n","    steps_per_epoch = 1638\n","    num_train_steps = steps_per_epoch * epochs\n","    num_warmup_steps = int(0.1*num_train_steps)\n","    init_lr = 1e-5\n","\n","    optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                        num_train_steps=num_train_steps,\n","                                        num_warmup_steps=num_warmup_steps,\n","                                        optimizer_type='adamw')\n","\n","    longformer = TFAutoModel.from_pretrained(model_path, config=config)\n","    model = create_avg_model(longformer)\n","    \n","    # Freeze the Longformer layer.\n","    model.layers[2].trainable = False\n","                                        \n","    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","    # Train the model with freezed longformer layer.\n","    history = model.fit(\n","        x=[train_tokens, train_attention],\n","        y=train_labels,\n","        batch_size=16,\n","        validation_data = ([val_tokens, val_attention], val_labels),\n","        validation_batch_size=16,\n","        epochs=epochs,\n","        class_weight=class_weight,\n","        # steps_per_epoch=steps_per_epoch,\n","        callbacks=[\n","            early_stopping_callback,\n","            PlotLearning(),\n","            # cp_callback(),\n","            # WandbCallback(),\n","        ]\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eYXxrI_uInyB","executionInfo":{"status":"error","timestamp":1655749907739,"user_tz":-180,"elapsed":146868,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"outputId":"db3728c0-c6e7-496a-c4fd-e5433fc2b080"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":["Fine tuning avg_embeddings model...\n"]},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n","- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/14\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f0a3fd3aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_train_function.<locals>.train_function at 0x7f0a3fd3aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-3274decfb91e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         callbacks=[\n\u001b[1;32m     50\u001b[0m             \u001b[0mearly_stopping_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mPlotLearning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0;31m# cp_callback(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# WandbCallback(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: 9 root error(s) found.\n  (0) INVALID_ARGUMENT: {{function_node __inference_train_function_914612}} Input 2 to node `model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd` with op ScatterNd must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd}}]]\n\n\t [[model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond]]\n\t [[TPUReplicate/_compile/_14477215776727129555/_6]]\n  (1) INVALID_ARGUMENT: {{function_node __inference_train_function_914612}} Input 2 to node `model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd` with op ScatterNd must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd}}]]\n\n\t [[model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond]]\n\t [[TPUReplicate/_compile/_14477215776727129555/_6]]\n\t [[tpu_compile_succeeded_assert/_6730903249214299707/_7/_439]]\n  (2) INVALID_ARGUMENT: {{function_node __inference_train_function_914612}} Input 2 to node `model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd` with op ScatterNd must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.\n\n\t [[{{node model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd}}]]\n\n\t [[model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond]]\n\t [[TPUReplicate/_compile/_14477215776727129555/_6]]\n\t [[tpu_compile_succeeded_assert/_6730903249214299707/_7/_415]]\n  (3) INVALID_ARGUMENT: {{function_node __inference_train_function_914612}} Input 2 to node `model/tf_longformer_model/longformer/encoder/layer_._0/attention/self/cond/ScatterNd` with op ScatterNd must be a compile-time constant.\n\nXLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compi ... [truncated]"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lAM5fKYVJUs5","executionInfo":{"status":"aborted","timestamp":1655749907738,"user_tz":-180,"elapsed":6,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["pprint(history.history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIlxc7QCu4Lm","executionInfo":{"status":"aborted","timestamp":1655743252760,"user_tz":-180,"elapsed":12,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["eval = model.evaluate(x=test_inputs, y=test_labels, batch_size=1)"]},{"cell_type":"code","source":["eval"],"metadata":{"id":"CnWqRl9xlqzb","executionInfo":{"status":"aborted","timestamp":1655743252760,"user_tz":-180,"elapsed":12,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99p3eq0_yXYD","executionInfo":{"status":"aborted","timestamp":1655743252760,"user_tz":-180,"elapsed":12,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.tight_layout()\n","\n","def plot_validation_curves(history):\n","    acc, val_acc, loss, val_loss = [], [], [], []\n","\n","    if type(history) == list:\n","        for inst in history:\n","            inst_dict = inst.history\n","\n","            acc.extend(inst_dict[\"binary_accuracy\"])\n","            val_acc.extend(inst_dict['val_binary_accuracy'])\n","            loss.extend(inst_dict['loss'])\n","            val_loss.extend(inst_dict['val_loss'])\n","    else:\n","        history_dict = history.history\n","        acc = history_dict['binary_accuracy']\n","        val_acc = history_dict['val_binary_accuracy']\n","        loss = history_dict['loss']\n","        val_loss = history_dict['val_loss']\n","    \n","    epochs = range(1, len(acc) + 1)\n","    fig = plt.figure(figsize=(16, 8))\n","    fig.tight_layout()\n","    \n","    plt.subplot(2, 1, 1)\n","    # r is for \"solid red line\"\n","    plt.plot(epochs, loss, 'r', label='Training loss')\n","    # b is for \"solid blue line\"\n","    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","    plt.title('Training and validation loss')\n","    # plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    \n","    plt.subplot(2, 1, 2)\n","    plt.plot(epochs, acc, 'r', label='Training acc')\n","    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend(loc='lower right')"]},{"cell_type":"code","source":["def get_probs(outputs):\n","    \"\"\"Returns the probabilities associated with the labels and the label with the highest score.\"\"\"\n","    probs = tf.nn.softmax(outputs[0], axis=-1)  # -1 is last dimension\n","    print(probs)\n","    mean = probs.mean(dim=0)\n","    print(mean)\n","    label = tf.math.argmax(mean).item()\n","    print(label)\n","\n","    return mean.to(\"cpu\"), label\n","\n","test_pred = []\n","for input in test_inputs:\n","    outputs = model(**input)\n","    _, label = get_probs(outputs)\n","\n","    test_pred.append(label)"],"metadata":{"id":"G-qVt11RPLL8","executionInfo":{"status":"aborted","timestamp":1655743252760,"user_tz":-180,"elapsed":12,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","\n","# Plot confusion matrix and scores.\n","cf_matrix = confusion_matrix(test_labels, test_pred)\n","\n","def show_confusion_matrix(cf_matrix):\n","    group_names = ['TN', 'FP', 'FN', 'TP']\n","    group_counts = ['{0:0.0f}'.format(value) for value in cf_matrix.flatten()]\n","    group_percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n","    labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n","    labels = np.asarray(labels).reshape(2,2)\n","    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')\n","    \n","show_confusion_matrix(cf_matrix)"],"metadata":{"id":"Efjhi8uyIMqU","executionInfo":{"status":"aborted","timestamp":1655743252761,"user_tz":-180,"elapsed":13,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"TPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Longformer - AVG.ipynb","provenance":[{"file_id":"1e9_ShLBqRQkMim1Si4pUOycgLXmAwC0b","timestamp":1655742614663}],"authorship_tag":"ABX9TyNw7aJD/fJzGa4i92sE6qpK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}