{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20925,"status":"ok","timestamp":1655716136565,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"3aNI3EEjVmz3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5c8015f4-c86c-4023-be7d-31480099a89d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 362 kB 34.4 MB/s \n","\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 76.7 MB/s \n","\u001b[K     |████████████████████████████████| 140 kB 91.3 MB/s \n","\u001b[K     |████████████████████████████████| 212 kB 63.5 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 11.4 MB/s \n","\u001b[K     |████████████████████████████████| 127 kB 56.0 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 72.0 MB/s \n","\u001b[K     |████████████████████████████████| 94 kB 4.0 MB/s \n","\u001b[K     |████████████████████████████████| 271 kB 23.7 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[K     |████████████████████████████████| 4.4 MB 25.0 MB/s \n","\u001b[K     |████████████████████████████████| 6.6 MB 56.1 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q datasets\n","!pip install -q transformers"]},{"cell_type":"code","source":["import os\n","import gc\n","import sys\n","import subprocess\n","import random\n","import numpy as np\n","import pandas as pd\n","from pprint import pprint\n","\n","import torch\n","import transformers\n","\n","from tqdm.auto import tqdm\n","\n","if \"google.colab\" in sys.modules:\n","    cmd = \"pip install --upgrade watermark blackcellmagic\"\n","    process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)"],"metadata":{"id":"Nd4dbg7j0If3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O3Pg16VCXniE"},"outputs":[],"source":["import torch\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25581,"status":"ok","timestamp":1655716168057,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"tHxbDe70W2LB","outputId":"76579853-c998-4277-c97c-30e555e45bc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","DRIVE = \"/content/drive/MyDrive/ColabData/\""]},{"cell_type":"code","source":["MODEL_MAX_LENGTH=4096\n","BATCH_SIZE=4"],"metadata":{"id":"gdkZjwHgz3KC"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22103,"status":"ok","timestamp":1655716190152,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"ovuuGbKTYhGe","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["ccd25d1277274dc1b4a358cb68ed6ff6","74957b6a2ed2422d883ff5f3da1a15c7","c4a249f65e4b48ee8d2dc936b68295a6","b2e87e33f81048bf873ac13c9bb34f5a","5b04ebb457ca4ea9af1ed808f922a7f7","812eaa4ea0454d9abe1ad0784debfcf1","23dbb727853744a4bbf6573e8b1d9556","061668eaf3204dc7b87d294bd9b4a9a9","a05311af0b0345e28d6b916f7103f6c1","8da89cbd495649579008336a58e015ca","8ccd9165ecbb4f22a0692e12ad861935","1c99ef25338d4c4bba08ae9c9eea1295","85bb4d5850cb4839bca55d638d31a7ea","db4204af015548a79b9a53973fe535ca","a87f0e868980412c8813bc91cc33841b","fb2193910fba4a62a4cb7358828e0450","2af1893e4ff64440bb6ee301de1d5f1c","f9ee92253d58404c96220ef4857742cd","18233a88a0c64ea18d89db8fa564198e","133b8a1eee614caba0a8e6e1c497abb1","d3a7c940c52f4265a42f236e0546f42a","380c5dceecac40f296719e8e3a15ca8d","c4a715251b754b5fa1357e21bf434978","840fc5eb0ee94f7ab0325d2c87b30771","7a70537dd0ed4355988d8f2f1dc85939","4a8496bce9134815b27402abc5e7d33c","04393c9bfb1f467c9a5bd04346f05a2d","881b6e0444b6490797c96988014607b6","5dae7d5ccd724441bd4b80af8005a997","a7cba273b5074cba821e15bf465b24a0","e16bf19d217c4aebbb1a1181c9259d96","53a3d72c997f412c98327f5ae6936751","0825ca37c4a04824b33d9e0c46572531","693cc9e9fb844e81b64dfb102aa84da3","c4832eb33010439b911a3ea0b2222e1b","7a7d858e7985409fa1a9b9cd719f4156","32cc6916c7fd48589fe66268aaa2e761","1d3c384f3e4b43cfb8e522ad5db25111","56288672993444cfa20e6926ab1bced3","f2bbf9f80c134de8ae8c514c820688d2","627325f3412b43059da786972f1c79ea","94aa7f38bb1b4d83bb42a2a8a8ec7271","c57373de66dd4da4806d7458e324215a","215b64c61b2c4539b2c72912fc74a41d"]},"outputId":"090ad2a9-309e-4959-ecd1-5b6836eed689"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/694 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccd25d1277274dc1b4a358cb68ed6ff6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c99ef25338d4c4bba08ae9c9eea1295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4a715251b754b5fa1357e21bf434978"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"693cc9e9fb844e81b64dfb102aa84da3"}},"metadata":{}}],"source":["from sklearn.model_selection import train_test_split\n","\n","tokenizer_path = \"allenai/longformer-base-4096\"\n","tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer_path)\n","tokenizer.model_max_len=MODEL_MAX_LENGTH\n","\n","def tokenize(text):\n","    return tokenizer(text, truncation=True, padding=True, max_length=MODEL_MAX_LENGTH)\n","\n","def split(texts, labels, val_size=0.20, test_size=0.25, random_state=42):\n","    train_texts, val_texts, train_labels, val_labels = train_test_split(\n","        texts, labels, stratify=labels, test_size=val_size, random_state=random_state\n","    )\n","    train_texts, test_texts, train_labels, test_labels = train_test_split(\n","        train_texts,\n","        train_labels,\n","        stratify=train_labels,\n","        test_size=test_size,\n","        random_state=random_state,\n","    )\n","\n","    return train_texts, train_labels, val_texts, val_labels, test_texts, test_labels\n","\n","ds_path = os.path.join(DRIVE, \"text_classification_dataset_2.pickle\")\n","raw_ds = pd.read_pickle(ds_path)\n","\n","# 20% test, 20% validation, 60% train.\n","train_texts, train_labels, val_texts, val_labels, test_texts, test_labels = split(\n","    raw_ds[\"text\"].to_list(), raw_ds[\"label\"].to_list()\n",")\n","\n","train_inputs = tokenize(train_texts)\n","test_inputs = tokenize(test_texts)\n","val_inputs = tokenize(val_texts)"]},{"cell_type":"code","source":["relevant, irrelevant = np.bincount(train_labels)\n","total = relevant + irrelevant\n","\n","weight_for_0 = (1 / irrelevant) * (total) / 2.0 \n","weight_for_1 = (1 / relevant) * (total) / 2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","class_weight_list = [weight_for_0, weight_for_1]\n","\n","print('Weight for irrelevant samples (0): {:.2f}'.format(weight_for_0))\n","print('Weight for relevant samples (1): {:.2f}'.format(weight_for_1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pb-t1P4m3oGc","executionInfo":{"status":"ok","timestamp":1655716190152,"user_tz":-180,"elapsed":7,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"outputId":"82fff658-c23a-4669-dbb9-25a3d769f999"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Weight for irrelevant samples (0): 1.51\n","Weight for relevant samples (1): 0.75\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","class CustomDataset(torch.utils.data.Dataset):\n","    \"\"\"\n","    Class to store the articles as PyTorch Dataset.\n","    \"\"\"\n","    \n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","        \n","    def __getitem__(self, idx):\n","        # An encoding can have keys such as input_ids and attention_mask\n","        # item is a dictionary which has the same keys as the encoding has\n","        # and the values are the idxth value of the corresponding key\n","        # (in PyTorch's tensor format).\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","    \n","    def __len__(self):\n","        return len(self.labels)\n","        \n","# Dataset & dataloader\n","train_dataset = CustomDataset(train_inputs, train_labels)\n","val_dataset = CustomDataset(val_inputs, val_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print('Created train & val datasets.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obH5pb46zl1R","executionInfo":{"status":"ok","timestamp":1655716190152,"user_tz":-180,"elapsed":6,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"}},"outputId":"bdc69473-b443-41ee-fa25-981436497ebd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Created train & val datasets.\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeDRNlFnofux"},"outputs":[],"source":["from datasets import load_metric\n","from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n","\n","\n","def compute_metrics(pred):\n","    labels = pred.label_ids\n","    preds = pred.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n","    acc = accuracy_score(labels, preds)\n","    return {\n","        'accuracy': acc,\n","        'f1': f1,\n","        'precision': precision,\n","        'recall': recall\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3702,"status":"ok","timestamp":1655716251079,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"koq2GO1C4gN-","outputId":"4ceceea7-cece-45b3-dae0-abfbcf2f0744"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n","Model config LongformerConfig {\n","  \"attention_mode\": \"longformer\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"attention_window\": 128,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": true,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"irrelevant\",\n","    \"1\": \"relevant\"\n","  },\n","  \"ignore_attention_mask\": false,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 4098,\n","  \"model_type\": \"longformer\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"sep_token_id\": 2,\n","  \"transformers_version\": \"4.20.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n","Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using cuda_amp half precision backend\n"]}],"source":["import numpy as np\n","from datetime import datetime\n","from transformers import Trainer, LongformerForSequenceClassification, TrainingArguments\n","\n","model_name = \"allenai/longformer-base-4096\"\n","model = LongformerForSequenceClassification.from_pretrained(model_name, num_labels=2, attention_window=128, gradient_checkpointing=True, id2label={0: 'irrelevant', 1: 'relevant'})\n","model.train()\n","model.to(torch.device(device))\n","\n","training_args = TrainingArguments(\n","    output_dir                  = os.path.join(DRIVE, 'results/finetune'),\n","    overwrite_output_dir        = True,\n","    logging_dir                 = os.path.join(DRIVE, 'logs'),\n","    load_best_model_at_end      = True,\n","    save_strategy               = \"epoch\",\n","    save_total_limit            = 1,\n","    evaluation_strategy         = \"epoch\",\n","    logging_steps               = 100,\n","    per_device_train_batch_size = 4,\n","    per_device_eval_batch_size  = 4,\n","    gradient_accumulation_steps = 4,\n","    learning_rate               = 1e-6,\n","    warmup_steps                = 500,\n","    weight_decay                = 0.01,\n","    num_train_epochs            = 6,\n","    disable_tqdm                = False, \n","    # report_to                   = \"wandb\",\n","    fp16                        = True,\n",")\n","\n","class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        labels = inputs.get(\"labels\")\n","\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","\n","        loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weight_list, dtype=torch.float).to(device))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss\n","\n","trainer = CustomTrainer(\n","    model                       = model,\n","    args                        = training_args,\n","    train_dataset               = train_dataset,\n","    eval_dataset                = val_dataset,\n","    compute_metrics             = compute_metrics,\n"," )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":552},"executionInfo":{"elapsed":536,"status":"error","timestamp":1655716251605,"user":{"displayName":"Vlad Vitan","userId":"08529414929886631328"},"user_tz":-180},"id":"1OS9GTxT4YYX","outputId":"b2de0cc1-83a7-4a72-d0b3-7c28b896fcc0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 1638\n","  Num Epochs = 6\n","  Instantaneous batch size per device = 4\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 4\n","  Total optimization steps = 612\n","Initializing global attention on CLS token...\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-cc1d060ddad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# class weight, data cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 if (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-c12febe5dbb5>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# loss_fct = torch.nn.CrossEntropyLoss(weight=torch.tensor(class_weight_list, dtype=torch.float).to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([4])) must be the same as input size (torch.Size([4, 2]))"]}],"source":["# class weight, data cleaning\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nt7ZreiftA4T"},"outputs":[],"source":["# Save model\n","trainer.save_model(os.path.join(DRIVE, 'pretrained_longformer_finetune_v0.4'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1I0ITbpEPNM"},"outputs":[],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"heOmn97lE0S3"},"outputs":[],"source":["from huggingface_hub import notebook_login\n","notebook_login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wzm9eeP9v3nb"},"outputs":[],"source":["from datetime import datetime\n","from transformers import LongformerForSequenceClassification, LongformerTokenizerFast\n","\n","\n","tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-base-4096\", max_length=4096, num_labels=2, id2label={0: 'irrelevant', 1: 'relevant'})\n","model = LongformerForSequenceClassification.from_pretrained(os.path.join(DRIVE, \"pretrained_longformer_finetune_v0.2\"))\n","model.save_pretrained(\"vlsb/cybersec-news-filter\")\n","\n","# device = \"cuda\"\n","# model.config.max_length = 4096\n","# model.eval()\n","# model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Je7NdP0zP1c3"},"outputs":[],"source":["def get_probs(outputs):\n","    \"\"\"Returns the probabilities associated with the labels and the label with the highest score.\"\"\"\n","    probs = torch.nn.functional.softmax(outputs[0], dim=-1)  # -1 is last dimension\n","    mean = probs.mean(dim=0)\n","\n","    # category that scored highest\n","    label = torch.argmax(mean).item()\n","    return mean.to(device), label\n","\n","\n","entry = {\"_id\":{\"$oid\":\"628eeecdec8c56c61dcdb740\"},\"title\":\"Popular PyPI Package 'ctx' and PHP Library 'phpass' Hijacked to Steal AWS Keys\",\"publish_time\":{\"$date\":\"2022-05-26T02:35:05.000Z\"},\"link\":\"https://thehackernews.com/2022/05/pypi-package-ctx-and-php-library-phpass.html\",\"text\":\"Two trojanized Python and PHP packages have been uncovered in what's yet another instance of a software supply chain attack targeting the open source ecosystem.  One of the packages in question is \\\"ctx,\\\" a Python module available in the PyPi repository. The other involves \\\"phpass,\\\" a PHP package that's been forked on GitHub to distribute a rogue update.  \\\"In both cases the attacker appears to have taken over packages that have not been updated in a while,\\\" the SANS Internet Storm Center (ISC) said, one of whose volunteer incident handlers, Yee Ching, analyzed the ctx package.  It's worth noting that ctx, prior to the latest release on May 21, 2022, was last published to PyPi on December 19, 2014. On the other hand, phpass hasn't received an update since it was uploaded to Packagist on August 31, 2012. Both the libraries have been removed from PyPi and GitHub.  At its core, the modifications are designed to exfiltrate AWS credentials to a Heroku URL named 'anti-theft-web.herokuapp[.]com.' \\\"It appears that the perpetrator is trying to obtain all the environment variables, encode them in Base64, and forward the data to a web app under the perpetrator's control,\\\" Ching said.  It's suspected that the attacker managed to gain unauthorized access to the maintainer's account to publish the new ctx version. Further investigation has revealed that the threat actor registered the expired domain used by the original maintainer on May 14, 2022.  Linux diff command executed on original ctx 0.1.2 Package and the \\\"new\\\" ctx 0.1.2 Package  \\\"With control over the original domain name, creating a corresponding email to receive a password reset email would be trivial,\\\" Ching added. \\\"After gaining access to the account, the perpetrator could remove the old package and upload the new backdoored versions.\\\"  Coincidentally, on May 10, 2022, security consultant Lance Vick disclosed how it's possible to purchase lapsed NPM maintainer email domains and subsequently use them to re-create maintainer emails and seize control of the packages.  What's more, a metadata analysis of 1.63 million JavaScript NPM packages conducted by academics from Microsoft and North Carolina State University last year uncovered 2,818 maintainer email addresses associated with expired domains, effectively allowing an attacker to hijack 8,494 packages by taking over the NPM accounts.  \\\"In general, any domain name can be purchased from a domain registrar allowing the purchaser to connect to an email hosting service to get a personal email address,\\\" the researchers said. \\\"An attacker can hijack a user's domain to take over an account associated with that email address.\\\"  Should the domain of a maintainer turn out to be expired, the threat actor can acquire the domain and alter the DNS mail exchange (MX) records to appropriate the maintainer's email address.  \\\"Looks like the phpass compromise happened because the owner of the package source - 'hautelook' deleted his account and then the attacker claimed the username,\\\" independent researcher Somdev Sangwan said in a series of tweets, detailing what's called a repository hijacking attack.  Public repositories of open source code such as Maven, NPM, Packages, PyPi, and RubyGems are a critical part of the software supply chain that many organizations rely on to develop applications.  On the flip side, this has also made them an attractive target for a variety of adversaries seeking to deliver malware.  This includes typosquatting, dependency confusion, and account takeover attacks, the latter of which could be leveraged to ship fraudulent versions of legitimate packages, leading to widespread supply chain compromises.  \\\"Developers are blindly trusting repositories and installing packages from these sources, assuming they are secure,\\\" DevSecOps firm JFrog said last year, adding how threat actors are using the repositories as a malware distribution vector and launch successful attacks on both developer and CI/CD machines in the pipeline.  UPDATE: An Istanbul-based security researcher has claimed responsibility for altering ctx and phpass packages with code to steal developers' AWS credentials, the latter of which used a technique called chainjacking to repurpose the maintainer's abandoned GitHub username to serve malicious code.  Yunus Aydn said he paid $5 to register the expired domain associated with the ctx project (figlief@figlief[.]com) and used the password reset mechanism to take control of the legitimate maintainer's account.  \\\"All this research DOES NOT contain any malicious activity,\\\" Aydn said in a post. \\\"I want to show how this simple attack affects +10M users and companies. ALL THE DATA THAT I RECEIVED IS DELETED AND NOT USED.\\\"\"}\n","\n","start = datetime.now()\n","inputs = tokenizer(entry[\"text\"], padding=\"max_length\", max_length=4096, return_tensors=\"pt\", truncation=True).to(device)\n","\n","# labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n","# outputs = model(**inputs, labels=labels)\n","\n","outputs = model(**inputs)\n","print(get_probs(outputs))\n","\n","end = datetime.now()\n","print(\"elapsed:\", (end-start))\n","\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsQ4a8wu_xXT"},"outputs":[],"source":["!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","\n","import psutil\n","import humanize\n","import os\n","\n","import GPUtil as GPU\n","\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_4bFMl84__Jj"},"outputs":[],"source":["# If GPU RAM Util > 0% => crash notebook on purpose\n","# !kill -9 -1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fGdHwlKAIne"},"outputs":[],"source":["from transformers import PyTorchBenchmark, PyTorchBenchmarkArguments\n","\n","# %env CUDA_VISIBLE_DEVICES=0\n","args = PyTorchBenchmarkArguments(models=[\"vlsb/cybersec-news-filter\"], batch_sizes=[1, 2, 4, 8], sequence_lengths=[512, 1024, 2048, 4096], cuda=False)\n","benchmark = PyTorchBenchmark(args)\n","\n","res = benchmark.run()\n","print(res)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ehK_VohxBCNe"},"outputs":[],"source":["from pprint import pprint\n","pprint(res)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Longformer fine-tuning.ipynb","provenance":[],"authorship_tag":"ABX9TyOlPyIDH305+5V1IE+gGUud"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ccd25d1277274dc1b4a358cb68ed6ff6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_74957b6a2ed2422d883ff5f3da1a15c7","IPY_MODEL_c4a249f65e4b48ee8d2dc936b68295a6","IPY_MODEL_b2e87e33f81048bf873ac13c9bb34f5a"],"layout":"IPY_MODEL_5b04ebb457ca4ea9af1ed808f922a7f7"}},"74957b6a2ed2422d883ff5f3da1a15c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_812eaa4ea0454d9abe1ad0784debfcf1","placeholder":"​","style":"IPY_MODEL_23dbb727853744a4bbf6573e8b1d9556","value":"Downloading: 100%"}},"c4a249f65e4b48ee8d2dc936b68295a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_061668eaf3204dc7b87d294bd9b4a9a9","max":694,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a05311af0b0345e28d6b916f7103f6c1","value":694}},"b2e87e33f81048bf873ac13c9bb34f5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8da89cbd495649579008336a58e015ca","placeholder":"​","style":"IPY_MODEL_8ccd9165ecbb4f22a0692e12ad861935","value":" 694/694 [00:00&lt;00:00, 26.5kB/s]"}},"5b04ebb457ca4ea9af1ed808f922a7f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"812eaa4ea0454d9abe1ad0784debfcf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23dbb727853744a4bbf6573e8b1d9556":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"061668eaf3204dc7b87d294bd9b4a9a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a05311af0b0345e28d6b916f7103f6c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8da89cbd495649579008336a58e015ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ccd9165ecbb4f22a0692e12ad861935":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c99ef25338d4c4bba08ae9c9eea1295":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85bb4d5850cb4839bca55d638d31a7ea","IPY_MODEL_db4204af015548a79b9a53973fe535ca","IPY_MODEL_a87f0e868980412c8813bc91cc33841b"],"layout":"IPY_MODEL_fb2193910fba4a62a4cb7358828e0450"}},"85bb4d5850cb4839bca55d638d31a7ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af1893e4ff64440bb6ee301de1d5f1c","placeholder":"​","style":"IPY_MODEL_f9ee92253d58404c96220ef4857742cd","value":"Downloading: 100%"}},"db4204af015548a79b9a53973fe535ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18233a88a0c64ea18d89db8fa564198e","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_133b8a1eee614caba0a8e6e1c497abb1","value":898823}},"a87f0e868980412c8813bc91cc33841b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3a7c940c52f4265a42f236e0546f42a","placeholder":"​","style":"IPY_MODEL_380c5dceecac40f296719e8e3a15ca8d","value":" 878k/878k [00:01&lt;00:00, 946kB/s]"}},"fb2193910fba4a62a4cb7358828e0450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af1893e4ff64440bb6ee301de1d5f1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9ee92253d58404c96220ef4857742cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18233a88a0c64ea18d89db8fa564198e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"133b8a1eee614caba0a8e6e1c497abb1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3a7c940c52f4265a42f236e0546f42a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"380c5dceecac40f296719e8e3a15ca8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4a715251b754b5fa1357e21bf434978":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_840fc5eb0ee94f7ab0325d2c87b30771","IPY_MODEL_7a70537dd0ed4355988d8f2f1dc85939","IPY_MODEL_4a8496bce9134815b27402abc5e7d33c"],"layout":"IPY_MODEL_04393c9bfb1f467c9a5bd04346f05a2d"}},"840fc5eb0ee94f7ab0325d2c87b30771":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_881b6e0444b6490797c96988014607b6","placeholder":"​","style":"IPY_MODEL_5dae7d5ccd724441bd4b80af8005a997","value":"Downloading: 100%"}},"7a70537dd0ed4355988d8f2f1dc85939":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7cba273b5074cba821e15bf465b24a0","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e16bf19d217c4aebbb1a1181c9259d96","value":456318}},"4a8496bce9134815b27402abc5e7d33c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53a3d72c997f412c98327f5ae6936751","placeholder":"​","style":"IPY_MODEL_0825ca37c4a04824b33d9e0c46572531","value":" 446k/446k [00:01&lt;00:00, 515kB/s]"}},"04393c9bfb1f467c9a5bd04346f05a2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"881b6e0444b6490797c96988014607b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dae7d5ccd724441bd4b80af8005a997":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7cba273b5074cba821e15bf465b24a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e16bf19d217c4aebbb1a1181c9259d96":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53a3d72c997f412c98327f5ae6936751":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0825ca37c4a04824b33d9e0c46572531":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"693cc9e9fb844e81b64dfb102aa84da3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c4832eb33010439b911a3ea0b2222e1b","IPY_MODEL_7a7d858e7985409fa1a9b9cd719f4156","IPY_MODEL_32cc6916c7fd48589fe66268aaa2e761"],"layout":"IPY_MODEL_1d3c384f3e4b43cfb8e522ad5db25111"}},"c4832eb33010439b911a3ea0b2222e1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56288672993444cfa20e6926ab1bced3","placeholder":"​","style":"IPY_MODEL_f2bbf9f80c134de8ae8c514c820688d2","value":"Downloading: 100%"}},"7a7d858e7985409fa1a9b9cd719f4156":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_627325f3412b43059da786972f1c79ea","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_94aa7f38bb1b4d83bb42a2a8a8ec7271","value":1355863}},"32cc6916c7fd48589fe66268aaa2e761":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c57373de66dd4da4806d7458e324215a","placeholder":"​","style":"IPY_MODEL_215b64c61b2c4539b2c72912fc74a41d","value":" 1.29M/1.29M [00:01&lt;00:00, 1.47MB/s]"}},"1d3c384f3e4b43cfb8e522ad5db25111":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56288672993444cfa20e6926ab1bced3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2bbf9f80c134de8ae8c514c820688d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"627325f3412b43059da786972f1c79ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94aa7f38bb1b4d83bb42a2a8a8ec7271":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c57373de66dd4da4806d7458e324215a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"215b64c61b2c4539b2c72912fc74a41d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}