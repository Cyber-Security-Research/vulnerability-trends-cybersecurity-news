#!/usr/bin/env python
"""
This script downloads article information of one URL. The results are stored in JSON-files in a sub-folder.
You need to adapt the variables url and basepath in order to use the script.
"""

import json
import os.path

from newsplease import NewsPlease

from web_crawler import get_url_list

# original news-please dict displays: authors, date_download, date_modify, date_publish,
# description, filename, image_url, language, localpath, maintext,
# source_domain, text, title, title_page, title_rss, url


def write_json_files():
    """
        Writes json to files from articles using news-please.
        Original news-please dict displays: authors, date_download, date_modify, date_publish,
        description, filename, image_url, language, localpath, maintext,
        source_domain, text, title, title_page, title_rss, url.

        Args:
            None
        Returns:
            None
    """
    for url in get_url_list():
        article = NewsPlease.from_url(url)

        article_dict = {
            'author': article.authors[0] if article.authors else [],
            'date_publish': article.date_publish,
            'maintext': article.maintext,
            'title': article.title,
            'url': article.url,
        }

        # String of JSON object with serializing datetime to JSON
        json_dump = json.dumps(article_dict, indent=4,
                               sort_keys=True, default=str)

        # write in a JSON file at output in 'article_files' directory
        save_path = 'web_crawler/article_files/'
        complete_name = os.path.join(save_path, article.filename)

        with open(complete_name, 'w') as outfile:
            outfile.write(json_dump)


if __name__ == "__main__":
    url_list = write_json_files()
